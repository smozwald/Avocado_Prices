{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the Relationship between Agricultural Prices and Vegetation Health"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##CURRENTLY CREATING A PANDAS DATAFRAME BY SCRAPING THE HTML ON THE WEBSITE\n",
    "\n",
    "The purpose of this notebook is to advance and develop my own skills in terms of data analysis, data visualization, and coding adeptability, by creating and answering a relevant research question. Due to my own interest, this project will focus on predicting the price of avocados based on environmental characteristics. It will involve finding a dataset (from Kaggle) and importing this as the dependent variable. A representative number of agricultural regions will then need to be found (GGE appears to have some stuff that is relevant) and then historical NDVI calculated. Will also need to account for lag effect.\n",
    "\n",
    "Data for historical avocado prices is available from http://www.hassavocadoboard.com/retail/volume-and-price-data. Will need to firstly collect and collate all avocado prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create the raw data files for each year of avocado data. No need to run if already done.\n",
    "##Due to issues with the excel tables when downloaded, HTML tables were scraped instead.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "startyear = 2004\n",
    "endyear = 2017\n",
    "\n",
    "del df\n",
    "del full_df\n",
    "for year in range(startyear, endyear+1):\n",
    "    \n",
    "    #import_location = \"Data/Raw/avocado_\" + str(year) + \".csv\"  #If saving data for later\n",
    "    if year > 2014:\n",
    "        price_page = requests.get(\"http://www.hassavocadoboard.com/retail/volume-and-price-data/historical-volume-and-price-data/\" + str(year)).text\n",
    "        soup = BeautifulSoup(price_page,\"html.parser\")\n",
    "        \n",
    "        ##Find the subsection of the page focussing on total avocado sales etc. in the US, not on the states. Returns array, first element has attributes.\n",
    "        total_soup = soup.find_all(id = \"rvpTotalUS\")\n",
    "        \n",
    "        ##There are a number of additional table features we don't want (two to be exact, which appear before the header and data sections).\n",
    "        ##Filter so that only table elements which don't have a class are returned.\n",
    "        table = total_soup[0].find_all('table', {'class': None}) # Grab the first table\n",
    "        ordered_table = []\n",
    "        for row in table:\n",
    "            this_row = row.find_all(\"td\")\n",
    "            new_row = [data.text for data in this_row]\n",
    "            ordered_table.append(new_row)\n",
    "        df = pd.DataFrame(ordered_table)\n",
    "        #Correcting header values\n",
    "        head_vals = df.iloc[0]\n",
    "        df = df[1:]\n",
    "        df.columns = head_vals\n",
    "        df.rename(columns={'ASP*':'Price'}, inplace=True)\n",
    "\n",
    "\n",
    "    else:\n",
    "        price_page = requests.get(\"http://www.hassavocadoboard.com/retail/volume-and-price-data/historical-volume-and-price-data/\" + str(year)).text\n",
    "        soup = BeautifulSoup(price_page,\"html.parser\")\n",
    "        table = soup.find_all('tr')\n",
    "        ordered_table = []\n",
    "        for row in table:\n",
    "            this_row = row.find_all('td')\n",
    "            if this_row == []:\n",
    "                this_row = row.find_all('th') #Tables are seperated into header and data\n",
    "            new_row= [data.text for data in this_row]\n",
    "            ordered_table.append(new_row)\n",
    "        df = pd.DataFrame(ordered_table)\n",
    "        #Correcting header values\n",
    "        head_vals = df.iloc[0]\n",
    "        df = df[1:]\n",
    "        df.columns = head_vals\n",
    "        df.rename(columns={'Average Price':'Price'}, inplace=True) #Align column names with other data format\n",
    "        df.rename(columns={'Bags':'Total Bagged'}, inplace=True)\n",
    "    \n",
    "    #append data)\n",
    "    if 'full_df' in globals():\n",
    "        full_df = full_df.append(df, ignore_index = True, sort = False)\n",
    "    else:\n",
    "        full_df = df\n",
    "    \n",
    "df = full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Alter the date formats, specify months and years as we will want to work with these.\n",
    "##Correct formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Save the df if you wish\n",
    "df.to_csv(\"Data/avocado_prices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
